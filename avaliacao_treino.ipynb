{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad776c6",
   "metadata": {},
   "source": [
    "# Documento de avalia√ß√£o do treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9733e7ad",
   "metadata": {},
   "source": [
    "## Pastas que cont√©m os arquivos resultados do treinamento.\n",
    "#### Pasta com os resultados apresentados e analisados\n",
    "- Pasta com ultimo treinamento realizado: dados\\processados\\treino 5\n",
    "    - Cont√©m:\n",
    "        - Melhor peso resultado do treinamento\n",
    "        - Hist√≥rico do treino em csv\n",
    "        - Plots resultados do treinamento\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7408dbc",
   "metadata": {},
   "source": [
    "### Configura√ß√£o e carregamento do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ca6637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports e configura√ß√µes carregados.\n"
     ]
    }
   ],
   "source": [
    "# C√©lula 1: Configura√ß√£o e Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Importa os m√≥dulos do seu projeto\n",
    "from src.config import PATHS, DATA_CONFIG, MODEL_CONFIG, VIZ_CONFIG\n",
    "from src.model import PINN_BlackScholes\n",
    "from src.physics import black_scholes_residual\n",
    "\n",
    "print(\"Imports e configura√ß√µes carregados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6903e923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√µes auxiliares definidas.\n"
     ]
    }
   ],
   "source": [
    "# C√©lula 2: Fun√ß√£o Auxiliar de Black-Scholes\n",
    "def black_scholes_call_numpy(S, K, T, r, sigma):\n",
    "    \"\"\"Fun√ß√£o anal√≠tica de Black-Scholes em NumPy para plotagem.\"\"\"\n",
    "    T = np.where(T <= 1e-8, 1e-8, T)\n",
    "    sigma = np.where(sigma <= 1e-8, 1e-8, sigma)\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "\n",
    "def delta_call_numpy(S, K, T, r, sigma):\n",
    "    \"\"\"Fun√ß√£o anal√≠tica do Delta de uma Call em NumPy.\"\"\"\n",
    "    T = np.where(T <= 1e-8, 1e-8, T)\n",
    "    sigma = np.where(sigma <= 1e-8, 1e-8, sigma)\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    return norm.cdf(d1)\n",
    "\n",
    "print(\"Fun√ß√µes auxiliares definidas.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43949a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 3: Carregar Modelo e Dados\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "stats_path = os.path.join(PATHS['model_save_dir'], 'data_stats.json')\n",
    "try:\n",
    "    with open(stats_path, 'r') as f:\n",
    "        data_stats = json.load(f)\n",
    "    print(\"üìä Estat√≠sticas de normaliza√ß√£o do treinamento original carregadas com sucesso.\")\n",
    "    print(data_stats)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo de estat√≠sticas '{stats_path}' n√£o encontrado. Execute o main.py para ger√°-lo.\")\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = PINN_BlackScholes(config=MODEL_CONFIG, data_stats=data_stats)\n",
    "\n",
    "# Carregar os pesos treinados\n",
    "weights_path = \"dados/processados/treino 5/best_model_weights.pth\"\n",
    "if os.path.exists(weights_path):\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Modelo carregado com sucesso de '{weights_path}' e movido para '{device}'.\")\n",
    "else:\n",
    "    print(f\"ERRO: Arquivo de pesos n√£o encontrado em '{weights_path}'.\")\n",
    "\n",
    "# Carregar o hist√≥rico de treinamento\n",
    "history_path = \"dados/processados/treino 5/training_history.csv\"\n",
    "if os.path.exists(history_path):\n",
    "    history_df = pd.read_csv(history_path)\n",
    "    print(\"Hist√≥rico de treinamento carregado.\")\n",
    "else:\n",
    "    history_df = None\n",
    "    print(\"Aviso: Arquivo de hist√≥rico de treinamento n√£o encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ab210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar estat√≠sticas do dataset (necess√°rio para o modelo)\n",
    "df_opcoes=pd.read_csv(\"../PINN_Opcoes_BR/dados/brutos/Databricks/PETR4_2024.csv\", sep=',')\n",
    "df_opcoes['time_to_maturity'] = df_opcoes['days_to_maturity'] / 252.0  # Convertendo dias para anos\n",
    "data_stats = {\n",
    "    'S_min': df_opcoes['spot_price'].min(), \n",
    "    'S_max': df_opcoes['spot_price'].max(),\n",
    "    'K_min': df_opcoes['strike'].min(), \n",
    "    'K_max': df_opcoes['strike'].max(),\n",
    "    'T_max': df_opcoes['time_to_maturity'].max(),\n",
    "}\n",
    "\n",
    "# C√©lula 4: Carregar e Preparar os Novos Dados para Avalia√ß√£o\n",
    "\n",
    "arquivo_para_avaliar = 'PETR4_2024.csv' \n",
    "\n",
    "\n",
    "file_path = os.path.join(PATHS['raw_data'], arquivo_para_avaliar)\n",
    "print(f\"Carregando e processando dados de '{file_path}'...\")\n",
    "\n",
    "# Carrega e limpa os dados\n",
    "df_teste = pd.read_csv(file_path)\n",
    "df_teste = df_teste[df_teste['option_type'] == 'CALL'].dropna()\n",
    "df_teste = df_teste[(df_teste['premium'] > 0) & (df_teste['days_to_maturity'] > 0) & (df_teste['volatility'] > 0)]\n",
    "df_teste['time_to_maturity'] = df_teste['days_to_maturity'] / 252.0\n",
    "df_teste['r'] =  pd.read_csv(PATHS['selic_data'])['Selic'].iloc[-1] / 100.0 \n",
    "\n",
    "df_teste['S_norm'] = (df_teste['spot_price'] - data_stats['S_min']) / (data_stats['S_max'] - data_stats['S_min'])\n",
    "df_teste['K_norm'] = (df_teste['strike'] - data_stats['K_min']) / (data_stats['K_max'] - data_stats['K_min'])\n",
    "df_teste['T_norm'] = df_teste['time_to_maturity'] / data_stats['T_max']\n",
    "\n",
    "# Prepara os tensores para o modelo\n",
    "input_features = ['S_norm', 'K_norm', 'T_norm', 'r', 'premium']\n",
    "X_teste = torch.tensor(df_teste[input_features].values, dtype=torch.float32).to(device)\n",
    "y_teste = torch.tensor(df_teste[['premium']].values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 5: Gerar Previs√µes e Analisar Resultados\n",
    "print(\"Gerando previs√µes com o modelo carregado...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_teste = model(X_teste)\n",
    "    price_pred = output_teste['price']\n",
    "    sigma_pred = output_teste['sigma']\n",
    "\n",
    "# Converte para NumPy para facilitar a plotagem\n",
    "price_real_np = y_teste.cpu().numpy().flatten()\n",
    "price_pred_np = price_pred.cpu().numpy().flatten()\n",
    "df_teste['price_pred_pinn'] = price_pred_np\n",
    "df_teste['sigma_pred_pinn'] = sigma_pred.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar val_loader a partir de df_opcoes \n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import unicodedata, re\n",
    "\n",
    "if 'df_opcoes' not in globals():\n",
    "    print(\"df_opcoes n√£o encontrado. Execute a c√©lula que carrega o CSV antes.\")\n",
    "else:\n",
    "    def norm_name(s):\n",
    "        s2 = str(s).strip().lower()\n",
    "        s2 = unicodedata.normalize('NFKD', s2).encode('ascii', 'ignore').decode('ascii')\n",
    "        s2 = re.sub(r'[\\s\\.-]+', '_', s2)\n",
    "        s2 = re.sub(r'[^0-9a-z_]', '', s2)\n",
    "        return s2\n",
    "\n",
    "    cols = list(df_opcoes.columns)\n",
    "    norm_map = {c: norm_name(c) for c in cols}\n",
    "\n",
    "    def find_column(candidates):\n",
    "        for cand in candidates:\n",
    "            for orig, norm in norm_map.items():\n",
    "                if norm == cand:\n",
    "                    return orig\n",
    "        for cand in candidates:\n",
    "            for orig, norm in norm_map.items():\n",
    "                if cand in norm:\n",
    "                    return orig\n",
    "        return None\n",
    "\n",
    "    spot_col = find_column(['spot_price', 'spot', 'price', 'preco', 'close', 'underlying_price'])\n",
    "    strike_col = find_column(['strike', 'k', 'strike_price', 'preco_exercicio'])\n",
    "    days_col = find_column(['days_to_maturity', 'days', 'dias', 'dias_para_vencimento'])\n",
    "    ttm_col = find_column(['time_to_maturity', 'ttm', 'maturity', 'tenor'])\n",
    "    premium_col = find_column(['premium', 'option_price', 'price', 'preco_opcao', 'last_price', 'preco'])\n",
    "\n",
    "    print(\"Colunas detectadas:\")\n",
    "    print(f\"  spot_col   -> {spot_col}\")\n",
    "    print(f\"  strike_col -> {strike_col}\")\n",
    "    print(f\"  days_col   -> {days_col}\")\n",
    "    print(f\"  ttm_col    -> {ttm_col}\")\n",
    "    print(f\"  premium_col-> {premium_col}\")\n",
    "    if not (spot_col and strike_col and (ttm_col or days_col)):\n",
    "        print(\"N√£o foi poss√≠vel identificar colunas essenciais (spot/strike/ttm). Liste as colunas dispon√≠veis abaixo e ajuste manualmente:\")\n",
    "        print(cols)\n",
    "    else:\n",
    "        df = df_opcoes.copy()\n",
    "        if ttm_col is None and days_col is not None:\n",
    "            df['time_to_maturity'] = df[days_col].astype(float) / 252.0\n",
    "            ttm_col_used = 'time_to_maturity'\n",
    "        else:\n",
    "            ttm_col_used = ttm_col if ttm_col is not None else 'time_to_maturity'\n",
    "\n",
    "        # garantir num√©rico\n",
    "        df[spot_col] = pd.to_numeric(df[spot_col], errors='coerce')\n",
    "        df[strike_col] = pd.to_numeric(df[strike_col], errors='coerce')\n",
    "        df[ttm_col_used] = pd.to_numeric(df[ttm_col_used], errors='coerce')\n",
    "\n",
    "        # preencher data_stats caso n√£o exista\n",
    "        S_min = float(df[spot_col].min())\n",
    "        S_max = float(df[spot_col].max())\n",
    "        K_min = float(df[strike_col].min())\n",
    "        K_max = float(df[strike_col].max())\n",
    "        T_max = float(df[ttm_col_used].max())\n",
    "        data_stats = {'S_min': S_min, 'S_max': S_max, 'K_min': K_min, 'K_max': K_max, 'T_max': T_max}\n",
    "        print(\"data_stats calculado:\", data_stats)\n",
    "\n",
    "        # features\n",
    "        S = df[spot_col].values\n",
    "        K = df[strike_col].values\n",
    "        T = df[ttm_col_used].values\n",
    "        S_n = (S - S_min) / (S_max - S_min)\n",
    "        K_n = (K - K_min) / (K_max - K_min)\n",
    "        T_n = T / T_max\n",
    "        r_fixed = 0.13\n",
    "        # premium input (se existir usar, sen√£o usar 1.0 placeholder)\n",
    "        if premium_col and premium_col in df.columns:\n",
    "            premium_in = pd.to_numeric(df[premium_col], errors='coerce').fillna(1.0).values\n",
    "        else:\n",
    "            premium_in = np.ones_like(S_n)\n",
    "\n",
    "        # target (market premium). preferir premium_col se claramente pre√ßo da op√ß√£o; caso contr√°rio tentar 'option_price' ou 'premium'\n",
    "        target = None\n",
    "        for cand in ['option_price','premium','last_price','price','preco_opcao','preco']:\n",
    "            col = find_column([cand])\n",
    "            if col and col in df.columns:\n",
    "                target = pd.to_numeric(df[col], errors='coerce').values\n",
    "                break\n",
    "        if target is None:\n",
    "            # se n√£o achou target, usar premium_in (mas avisa)\n",
    "            target = premium_in\n",
    "            print(\"Aviso: n√£o foi encontrado target claro para pre√ßo de op√ß√£o; usando coluna de premium/placeholder como target.\")\n",
    "\n",
    "        # remover linhas com NaN\n",
    "        mask = (~np.isnan(S_n)) & (~np.isnan(K_n)) & (~np.isnan(T_n)) & (~np.isnan(target))\n",
    "        X = np.vstack([S_n[mask], K_n[mask], T_n[mask], np.full(mask.sum(), r_fixed), premium_in[mask]]).T\n",
    "        y = target[mask].astype(np.float32)\n",
    "\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "        # split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_tensor.numpy(), y_tensor.numpy(), test_size=0.2, random_state=42)\n",
    "        val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
    "        batch_size = 1024\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "        print(f\"val_loader criado com {len(val_ds)} amostras (batch_size={batch_size}).\")\n",
    "# C√âLULA: Criar val_loader a partir de df_opcoes (executar)\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import unicodedata, re\n",
    "\n",
    "if 'df_opcoes' not in globals():\n",
    "    print(\"df_opcoes n√£o encontrado. Execute a c√©lula que carrega o CSV antes.\")\n",
    "else:\n",
    "    def norm_name(s):\n",
    "        s2 = str(s).strip().lower()\n",
    "        s2 = unicodedata.normalize('NFKD', s2).encode('ascii', 'ignore').decode('ascii')\n",
    "        s2 = re.sub(r'[\\s\\.-]+', '_', s2)\n",
    "        s2 = re.sub(r'[^0-9a-z_]', '', s2)\n",
    "        return s2\n",
    "\n",
    "    cols = list(df_opcoes.columns)\n",
    "    norm_map = {c: norm_name(c) for c in cols}\n",
    "\n",
    "    def find_column(candidates):\n",
    "        for cand in candidates:\n",
    "            for orig, norm in norm_map.items():\n",
    "                if norm == cand:\n",
    "                    return orig\n",
    "        for cand in candidates:\n",
    "            for orig, norm in norm_map.items():\n",
    "                if cand in norm:\n",
    "                    return orig\n",
    "        return None\n",
    "\n",
    "    spot_col = find_column(['spot_price', 'spot', 'price', 'preco', 'close', 'underlying_price'])\n",
    "    strike_col = find_column(['strike', 'k', 'strike_price', 'preco_exercicio'])\n",
    "    days_col = find_column(['days_to_maturity', 'days', 'dias', 'dias_para_vencimento'])\n",
    "    ttm_col = find_column(['time_to_maturity', 'ttm', 'maturity', 'tenor'])\n",
    "    premium_col = find_column(['premium', 'option_price', 'price', 'preco_opcao', 'last_price', 'preco'])\n",
    "\n",
    "    print(\"Colunas detectadas:\")\n",
    "    print(f\"  spot_col   -> {spot_col}\")\n",
    "    print(f\"  strike_col -> {strike_col}\")\n",
    "    print(f\"  days_col   -> {days_col}\")\n",
    "    print(f\"  ttm_col    -> {ttm_col}\")\n",
    "    print(f\"  premium_col-> {premium_col}\")\n",
    "    if not (spot_col and strike_col and (ttm_col or days_col)):\n",
    "        print(\"N√£o foi poss√≠vel identificar colunas essenciais (spot/strike/ttm). Liste as colunas dispon√≠veis abaixo e ajuste manualmente:\")\n",
    "        print(cols)\n",
    "    else:\n",
    "        df = df_opcoes.copy()\n",
    "        if ttm_col is None and days_col is not None:\n",
    "            df['time_to_maturity'] = df[days_col].astype(float) / 252.0\n",
    "            ttm_col_used = 'time_to_maturity'\n",
    "        else:\n",
    "            ttm_col_used = ttm_col if ttm_col is not None else 'time_to_maturity'\n",
    "\n",
    "        # garantir num√©rico\n",
    "        df[spot_col] = pd.to_numeric(df[spot_col], errors='coerce')\n",
    "        df[strike_col] = pd.to_numeric(df[strike_col], errors='coerce')\n",
    "        df[ttm_col_used] = pd.to_numeric(df[ttm_col_used], errors='coerce')\n",
    "\n",
    "        # preencher data_stats caso n√£o exista\n",
    "        S_min = float(df[spot_col].min())\n",
    "        S_max = float(df[spot_col].max())\n",
    "        K_min = float(df[strike_col].min())\n",
    "        K_max = float(df[strike_col].max())\n",
    "        T_max = float(df[ttm_col_used].max())\n",
    "        data_stats = {'S_min': S_min, 'S_max': S_max, 'K_min': K_min, 'K_max': K_max, 'T_max': T_max}\n",
    "        print(\"data_stats calculado:\", data_stats)\n",
    "\n",
    "        # features\n",
    "        S = df[spot_col].values\n",
    "        K = df[strike_col].values\n",
    "        T = df[ttm_col_used].values\n",
    "        S_n = (S - S_min) / (S_max - S_min)\n",
    "        K_n = (K - K_min) / (K_max - K_min)\n",
    "        T_n = T / T_max\n",
    "        r_fixed = 0.13\n",
    "        # premium input (se existir usar, sen√£o usar 1.0 placeholder)\n",
    "        if premium_col and premium_col in df.columns:\n",
    "            premium_in = pd.to_numeric(df[premium_col], errors='coerce').fillna(1.0).values\n",
    "        else:\n",
    "            premium_in = np.ones_like(S_n)\n",
    "\n",
    "        # target (market premium). preferir premium_col se claramente pre√ßo da op√ß√£o; caso contr√°rio tentar 'option_price' ou 'premium'\n",
    "        target = None\n",
    "        for cand in ['option_price','premium','last_price','price','preco_opcao','preco']:\n",
    "            col = find_column([cand])\n",
    "            if col and col in df.columns:\n",
    "                target = pd.to_numeric(df[col], errors='coerce').values\n",
    "                break\n",
    "        if target is None:\n",
    "            # se n√£o achou target, usar premium_in (mas avisa)\n",
    "            target = premium_in\n",
    "            print(\"Aviso: n√£o foi encontrado target claro para pre√ßo de op√ß√£o; usando coluna de premium/placeholder como target.\")\n",
    "\n",
    "        # remover linhas com NaN\n",
    "        mask = (~np.isnan(S_n)) & (~np.isnan(K_n)) & (~np.isnan(T_n)) & (~np.isnan(target))\n",
    "        X = np.vstack([S_n[mask], K_n[mask], T_n[mask], np.full(mask.sum(), r_fixed), premium_in[mask]]).T\n",
    "        y = target[mask].astype(np.float32)\n",
    "\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "        # split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_tensor.numpy(), y_tensor.numpy(), test_size=0.2, random_state=42)\n",
    "        val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
    "        batch_size = 1024\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "        print(f\"val_loader criado com {len(val_ds)} amostras (batch_size={batch_size}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffd0c5",
   "metadata": {},
   "source": [
    "## Gr√°ficos de para an√°lise:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001794a",
   "metadata": {},
   "source": [
    "Preparo da grade para superf√≠cies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar grade para superf√≠cies (executa ao rodar)\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "resolution = 50  # ajuste conforme necess√°rio\n",
    "print(f\"Preparando grade com resolu√ß√£o = {resolution}...\")\n",
    "moneyness_vals = torch.linspace(0.8, 1.2, resolution, device=device)\n",
    "T_norm_vals = torch.linspace(0.01, 1.0, resolution, device=device)\n",
    "M_grid, T_grid = torch.meshgrid(moneyness_vals, T_norm_vals, indexing='ij')\n",
    "\n",
    "K_fixed = (data_stats['K_max'] + data_stats['K_min']) / 2\n",
    "S_vals = M_grid * K_fixed\n",
    "\n",
    "S_norm_grid = (S_vals - data_stats['S_min']) / (data_stats['S_max'] - data_stats['S_min'])\n",
    "K_norm_fixed = (K_fixed - data_stats['K_min']) / (data_stats['K_max'] - data_stats['K_min'])\n",
    "K_norm_grid = torch.full_like(S_norm_grid, K_norm_fixed)\n",
    "\n",
    "r_grid = torch.full_like(S_norm_grid, 0.13)\n",
    "premium_grid = torch.full_like(S_norm_grid, 1.0)\n",
    "\n",
    "model_input = torch.stack([\n",
    "    S_norm_grid.flatten(), K_norm_grid.flatten(), T_grid.flatten(),\n",
    "    r_grid.flatten(), premium_grid.flatten()\n",
    "], dim=1).to(device)\n",
    "print(\"Grade e model_input prontos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393b1b0",
   "metadata": {},
   "source": [
    "### An√°lise do Loss durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b80fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot do hist√≥rico de perdas (executa ao rodar)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'history_df' not in globals() or history_df is None:\n",
    "    print(\"Hist√≥rico n√£o dispon√≠vel (history_df is None). Pule esta c√©lula ap√≥s carregar o hist√≥rico.\")\n",
    "else:\n",
    "    print(\"Gerando gr√°fico do hist√≥rico de perdas...\")\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    ax1.plot(history_df['train_loss'], label='Perda de Treinamento', color='blue')\n",
    "    ax1.plot(history_df['val_loss'], label='Perda de Valida√ß√£o', color='orange')\n",
    "    ax1.set_xlabel('√âpoca')\n",
    "    ax1.set_ylabel('Loss (MSE)', color='blue')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax1.grid(True, which=\"both\", ls=\"--\", axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    if 'lr' in history_df.columns:\n",
    "        ax2.plot(history_df['lr'], label='Taxa de Aprendizado (LR)', color='green', linestyle='--')\n",
    "    ax2.set_ylabel('Taxa de Aprendizado', color='green')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "    fig.suptitle('Hist√≥rico de Perdas e Taxa de Aprendizado')\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    fig.legend(lines + lines2, labels + labels2, loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes)\n",
    "\n",
    "    os.makedirs(PATHS['plot_save_dir'], exist_ok=True)\n",
    "    save_path = os.path.join(PATHS['plot_save_dir'], 'loss_history.png')\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print(f\"Gr√°fico de perdas salvo em: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapa de calor do res√≠duo da PDE (processado em batches com grad)\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 1024\n",
    "N = model_input.shape[0]\n",
    "residual_all = np.zeros(N, dtype=float)\n",
    "\n",
    "model.train()  # precisamos de grad, mas usaremos create_graph dentro da fun√ß√£o\n",
    "for start in range(0, N, batch_size):\n",
    "    end = min(start + batch_size, N)\n",
    "    inp = model_input[start:end].clone().detach().requires_grad_(True)\n",
    "    out = model(inp)\n",
    "    # black_scholes_residual espera (output_phy, inputs, data_stats) ‚Äî ajustado ao seu m√≥dulo\n",
    "    res = black_scholes_residual(out, inp, data_stats)\n",
    "    residual_all[start:end] = torch.abs(res).cpu().detach().numpy().flatten()\n",
    "print(\"C√°lculo do res√≠duo conclu√≠do.\")\n",
    "\n",
    "residual_grid = residual_all.reshape(M_grid.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "M_cpu = M_grid.cpu().numpy()\n",
    "T_cpu = T_grid.cpu().numpy() * data_stats['T_max'] * 252\n",
    "c = ax.pcolormesh(M_cpu, T_cpu, residual_grid, cmap='hot', shading='gouraud', vmax=np.percentile(residual_grid, 99))\n",
    "ax.set_title('Mapa de Calor do Res√≠duo Absoluto da EDP de Black-Scholes')\n",
    "ax.set_xlabel('Moneyness (S/K)')\n",
    "ax.set_ylabel('Dias para o Vencimento')\n",
    "fig.colorbar(c, ax=ax, label='|Res√≠duo da EDP|')\n",
    "\n",
    "os.makedirs(PATHS['plot_save_dir'], exist_ok=True)\n",
    "save_path = os.path.join(PATHS['plot_save_dir'], 'pde_residual_surface.png')\n",
    "fig.savefig(save_path, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"Gr√°fico do res√≠duo da EDP salvo em: {save_path}\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolu√ß√£o dos Pesos da Perda\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Eixo esquerdo para o peso dos dados\n",
    "ax1.plot(history_df['weight_data'], label='Peso da Perda de Dados (Œª_data)', color='deepskyblue')\n",
    "ax1.set_xlabel('√âpoca')\n",
    "ax1.set_ylabel('Peso da Perda de Dados', color='deepskyblue')\n",
    "ax1.set_yscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='deepskyblue')\n",
    "ax1.grid(True, which=\"both\", ls=\"--\", axis='y')        \n",
    "# Eixo direito para o peso da f√≠sica (PDE)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(history_df['weight_pde'], label='Peso da Perda da F√≠sica (Œª_pde)', color='crimson', linestyle='--')\n",
    "ax2.set_ylabel('Peso da Perda da F√≠sica', color='crimson')\n",
    "ax2.set_yscale('log')\n",
    "ax2.tick_params(axis='y', labelcolor='crimson')\n",
    "fig.suptitle('Evolu√ß√£o dos Pesos da Perda (Pondera√ß√£o Adaptativa)')\n",
    "# Coleta os handles e labels de ambos os eixos para uma legenda unificada\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49bd724",
   "metadata": {},
   "source": [
    "### An√°lise do Delta e das Gregas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ebc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acur√°cia das Gregas (Delta)\n",
    "moneyness_vals = torch.linspace(0.8, 1.2, 100, device=device)\n",
    "T_norm_vals = torch.tensor([0.1, 0.5, 0.9], device=device) # Vencimentos curto, m√©dio e longo\n",
    "\n",
    "K_fixed = (data_stats['K_max'] + data_stats['K_min']) / 2\n",
    "K_norm_fixed = (K_fixed - data_stats['K_min']) / (data_stats['K_max'] - data_stats['K_min'])\n",
    "r_fixed = 0.13\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "for T_n in T_norm_vals:\n",
    "    S_vals = moneyness_vals * K_fixed\n",
    "    S_norm_vals = (S_vals - data_stats['S_min']) / (data_stats['S_max'] - data_stats['S_min'])\n",
    "    \n",
    "    inputs = torch.stack([\n",
    "        S_norm_vals,\n",
    "        torch.full_like(S_norm_vals, K_norm_fixed),\n",
    "        torch.full_like(S_norm_vals, T_n.item()),\n",
    "        torch.full_like(S_norm_vals, r_fixed),\n",
    "        torch.ones_like(S_norm_vals) # Premium placeholder\n",
    "    ], dim=1).requires_grad_(True)\n",
    "    \n",
    "    output = model(inputs)\n",
    "    V = output['price']\n",
    "    sigma_pinn = output['sigma']\n",
    "    \n",
    "    # Delta da PINN (via Autograd)\n",
    "    V_grads = torch.autograd.grad(V.sum(), inputs, create_graph=True)[0]\n",
    "    V_S_norm = V_grads[:, 0]\n",
    "    delta_pinn = V_S_norm / (data_stats['S_max'] - data_stats['S_min'])\n",
    "    \n",
    "    # Delta Anal√≠tico (usando a vol da PINN)\n",
    "    T_val = (T_n * data_stats['T_max']).item()\n",
    "    delta_bs = delta_call_numpy(S_vals.cpu().detach().numpy(), K_fixed, T_val, r_fixed, sigma_pinn.cpu().detach().numpy().flatten())\n",
    "    \n",
    "    plt.plot(moneyness_vals.cpu().numpy(), delta_pinn.cpu().detach().numpy(), label=f'Delta PINN (T={T_val*252:.0f} dias)')\n",
    "    plt.plot(moneyness_vals.cpu().numpy(), delta_bs, '--', label=f'Delta Anal√≠tico (T={T_val*252:.0f} dias)')\n",
    "\n",
    "plt.title(\"Compara√ß√£o do Delta (PINN vs. Anal√≠tico)\")\n",
    "plt.xlabel(\"Moneyness (S/K)\")\n",
    "plt.ylabel(\"Delta (‚àÇV/‚àÇS)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "save_path = os.path.join(PATHS['plot_save_dir'], 'delta_accuracy.png')\n",
    "fig.savefig(save_path)\n",
    "print(f\"Gr√°fico de acur√°cia do Delta salvo em: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superf√≠cie do Delta Aprendido pela PINN\n",
    "\n",
    "def prepare_surface_data(resolution=50): # Resolu√ß√£o menor para testes mais r√°pidos\n",
    "    moneyness_vals = torch.linspace(0.8, 1.2, resolution, device=device)\n",
    "    T_norm_vals = torch.linspace(0.01, 1, resolution, device=device)        \n",
    "    M_grid, T_grid = torch.meshgrid(moneyness_vals, T_norm_vals, indexing='ij')        \n",
    "    K_fixed = (data_stats['K_max'] + data_stats['K_min']) / 2\n",
    "    S_vals = M_grid * K_fixed\n",
    "    S_norm_grid = (S_vals - data_stats['S_min']) / (data_stats['S_max'] - data_stats['S_min'])\n",
    "    K_norm_fixed = (K_fixed - data_stats['K_min']) / (data_stats['K_max'] - data_stats['K_min'])\n",
    "    K_norm_grid = torch.full_like(S_norm_grid, K_norm_fixed)\n",
    "    r_grid = torch.full_like(S_norm_grid, 0.13)\n",
    "    premium_grid = torch.full_like(S_norm_grid, 1.0)\n",
    "    model_input = torch.stack([\n",
    "        S_norm_grid.flatten(), K_norm_grid.flatten(), T_grid.flatten(), \n",
    "        r_grid.flatten(), premium_grid.flatten()\n",
    "    ], dim=1)        \n",
    "    return M_grid, T_grid, model_input\n",
    "\n",
    "M_grid, T_grid, model_input = prepare_surface_data()\n",
    "model_input.requires_grad = True\n",
    "output = model(model_input)\n",
    "V = output['price']\n",
    "V_grads = torch.autograd.grad(V, model_input, grad_outputs=torch.ones_like(V), create_graph=True)[0]\n",
    "V_S_norm = V_grads[:, 0]        \n",
    "delta = V_S_norm / (data_stats['S_max'] - data_stats['S_min'])\n",
    "delta_surface = delta.reshape_as(M_grid)\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "M_cpu = M_grid.cpu().detach().numpy()\n",
    "T_cpu = T_grid.cpu().detach().numpy() * data_stats['T_max'] * 252\n",
    "delta_cpu = delta_surface.cpu().detach().numpy()        \n",
    "surf = ax.plot_surface(M_cpu, T_cpu, delta_cpu, cmap='cividis', edgecolor='none')\n",
    "ax.set_title('Superf√≠cie do Delta Aprendido pela PINN')\n",
    "ax.set_xlabel('Moneyness (S/K)')\n",
    "ax.set_ylabel('Dias para o Vencimento')\n",
    "ax.set_zlabel('Delta (‚àÇV/‚àÇS)')\n",
    "ax.set_zlim(0, 1)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91223b0",
   "metadata": {},
   "source": [
    "### An√°lise da superf√≠cie da predi√ß√£o do PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara√ß√£o de superf√≠cies de pre√ßo (PINN vs. Anal√≠tico)\n",
    "resolution=40\n",
    "s_vals = np.linspace(data_stats['S_min'], data_stats['S_max'], resolution)\n",
    "t_vals = np.linspace(0.01, data_stats['T_max'], resolution)\n",
    "S_grid, T_grid = np.meshgrid(s_vals, t_vals)\n",
    "K_fixed = (data_stats['K_max'] + data_stats['K_min']) / 2\n",
    "r_fixed = 0.13\n",
    "C_pinn = np.zeros_like(S_grid)\n",
    "sigma_pinn_grid = np.zeros_like(S_grid)\n",
    "with torch.no_grad():\n",
    "    for i in range(resolution):\n",
    "        for j in range(resolution):\n",
    "            S, T = S_grid[i, j], T_grid[i, j]\n",
    "            S_n = (S - data_stats['S_min']) / (data_stats['S_max'] - data_stats['S_min'])\n",
    "            T_n = T / data_stats['T_max']\n",
    "            K_n = (K_fixed - data_stats['K_min']) / (data_stats['K_max'] - data_stats['K_min'])\n",
    "            inp = torch.tensor([[S_n, K_n, T_n, r_fixed, 1.0]], dtype=torch.float32).to(device)\n",
    "            output = model(inp)\n",
    "            C_pinn[i, j] = output['price'].item()\n",
    "            sigma_pinn_grid[i, j] = output['sigma'].item()\n",
    "C_bs = black_scholes_call_numpy(S_grid, K_fixed, T_grid, r_fixed, np.mean(sigma_pinn_grid))\n",
    "fig = plt.figure(figsize=(16, 7))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax1.plot_surface(S_grid, T_grid * 252, C_pinn, cmap='viridis')\n",
    "ax1.set_title(\"Superf√≠cie de Pre√ßo da PINN\")\n",
    "ax1.set_xlabel('Pre√ßo do Ativo (S)'); ax1.set_ylabel('Dias para Vencimento'); ax1.set_zlabel('Pre√ßo da Op√ß√£o (V)')\n",
    "ax2.plot_surface(S_grid, T_grid * 252, C_bs, cmap='plasma')\n",
    "ax2.set_title(\"Superf√≠cie Anal√≠tica de Black-Scholes (Vol M√©dia da PINN)\")\n",
    "ax2.set_xlabel('Pre√ßo do Ativo (S)'); ax2.set_ylabel('Dias para Vencimento'); ax2.set_zlabel('Pre√ßo da Op√ß√£o (V)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√£o vs Real (scatter) - usa val_loader do notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'val_loader' not in globals():\n",
    "    print(\"val_loader n√£o encontrado. Crie/defina val_loader antes de rodar esta c√©lula.\")\n",
    "else:\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, premiums_real in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            price_pred = model(inputs)['price'].cpu().numpy().flatten()\n",
    "            actuals.extend(premiums_real.cpu().numpy().flatten())\n",
    "            predictions.extend(price_pred)\n",
    "    actuals = np.array(actuals)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(actuals, predictions, alpha=0.3, label='Previs√µes do Modelo')\n",
    "    min_val = min(actuals.min(), predictions.min())\n",
    "    max_val = max(actuals.max(), predictions.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Linha de Perfei√ß√£o (y=x)')\n",
    "    plt.xlabel('Pre√ßo de Mercado Real (Pr√™mio)')\n",
    "    plt.ylabel('Pre√ßo Previsto pela PINN')\n",
    "    plt.title('Compara√ß√£o entre Pre√ßo Real e Previsto (Conjunto de Valida√ß√£o)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "\n",
    "    os.makedirs(PATHS['plot_save_dir'], exist_ok=True)\n",
    "    save_path = os.path.join(PATHS['plot_save_dir'], 'prediction_vs_actual.png')\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print(f\"Gr√°fico de compara√ß√£o de pre√ßos salvo em: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superf√≠cie de Erro de Precifica√ß√£o\n",
    "resolution = 50\n",
    "s_vals = np.linspace(data_stats['S_min'], data_stats['S_max'], resolution)\n",
    "t_vals = np.linspace(0.01, data_stats['T_max'], resolution)\n",
    "S_grid, T_grid = np.meshgrid(s_vals, t_vals)\n",
    "K_fixed = (data_stats['K_max'] + data_stats['K_min']) / 2\n",
    "r_fixed = 0.13\n",
    "\n",
    "C_pinn = np.zeros_like(S_grid)\n",
    "sigma_pinn_grid = np.zeros_like(S_grid)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(resolution):\n",
    "        for j in range(resolution):\n",
    "            S, T = S_grid[i, j], T_grid[i, j]\n",
    "            S_n = (S - data_stats['S_min']) / (data_stats['S_max'] - data_stats['S_min'])\n",
    "            T_n = T / data_stats['T_max']\n",
    "            K_n = (K_fixed - data_stats['K_min']) / (data_stats['K_max'] - data_stats['K_min'])\n",
    "            inp = torch.tensor([[S_n, K_n, T_n, r_fixed, 1.0]], dtype=torch.float32).to(device)\n",
    "            output = model(inp)\n",
    "            C_pinn[i, j] = output['price'].item()\n",
    "            sigma_pinn_grid[i, j] = output['sigma'].item()\n",
    "\n",
    "C_bs = black_scholes_call_numpy(S_grid, K_fixed, T_grid, r_fixed, np.mean(sigma_pinn_grid))\n",
    "Price_Error_Surface = np.abs(C_pinn - C_bs)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(S_grid, T_grid * 252, Price_Error_Surface, cmap='hot')\n",
    "ax.set_title(\"Superf√≠cie de Erro Absoluto de Pre√ßo (PINN vs. BS Anal√≠tico)\")\n",
    "ax.set_xlabel('Pre√ßo do Ativo (S)')\n",
    "ax.set_ylabel('Dias para Vencimento')\n",
    "ax.set_zlabel('Erro Absoluto de Pre√ßo')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()\n",
    "save_path = os.path.join(PATHS['plot_save_dir'], 'price_error_surface.png')\n",
    "fig.savefig(save_path)\n",
    "print(f\"Gr√°fico da superf√≠cie de erro de pre√ßo salvo em: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13faa939",
   "metadata": {},
   "source": [
    "### An√°lise da superf√≠cie da volatilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Superf√≠cie de Volatilidade Impl√≠cita Aprendida (PINN)\n",
    "M_grid, T_grid, model_input = prepare_surface_data()\n",
    "with torch.no_grad():\n",
    "    sigma_pred = model(model_input)['sigma'].reshape_as(M_grid) * 100\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')        \n",
    "M_cpu = M_grid.cpu().numpy()\n",
    "T_cpu = T_grid.cpu().numpy() * data_stats['T_max'] * 252\n",
    "sigma_cpu = sigma_pred.cpu().numpy()\n",
    "surf = ax.plot_surface(M_cpu, T_cpu, sigma_cpu, cmap='viridis', edgecolor='none')        \n",
    "ax.set_title('Superf√≠cie de Volatilidade Impl√≠cita Aprendida (PINN)')\n",
    "ax.set_xlabel('Moneyness (S/K)')\n",
    "ax.set_ylabel('Dias para o Vencimento')\n",
    "ax.set_zlabel('Volatilidade Impl√≠cita (%)')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva de Volatilidade Impl√≠cita Aprendida\n",
    "\n",
    "model.eval()\n",
    "vol_real_list = []\n",
    "vol_pred_list = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader:\n",
    "        # A volatilidade real (hist√≥rica) n√£o √© usada no input, mas a temos no dataset\n",
    "        # Vamos reconstruir o input sem a vol para o modelo, mas guardar a vol para compara√ß√£o\n",
    "        # A 5¬™ coluna (√≠ndice 4) √© o pr√™mio, a vol n√£o est√° aqui. Precisamos carregar os dados completos.\n",
    "        pass # Esta l√≥gica precisa ser ajustada para ter acesso √† volatilidade original\n",
    "# SIMPLIFICA√á√ÉO: Para este exemplo, vamos plotar a vol prevista em rela√ß√£o ao moneyness\n",
    "M_grid, _, model_input = prepare_surface_data(resolution=100)\n",
    "with torch.no_grad():\n",
    "    sigma_pred = model(model_input)['sigma'].reshape_as(M_grid) * 100        \n",
    "plt.figure(figsize=(10, 7))\n",
    "# Plotamos um \"corte\" da superf√≠cie de volatilidade para um vencimento m√©dio\n",
    "T_median_idx = sigma_pred.shape[1] // 2\n",
    "plt.plot(M_grid[:, T_median_idx].cpu().numpy(), sigma_pred[:, T_median_idx].cpu().numpy(), label=f'Corte da Vol. Impl√≠cita (PINN)')        \n",
    "plt.xlabel('Moneyness (S/K)')\n",
    "plt.ylabel('Volatilidade Impl√≠cita (%)')\n",
    "plt.title('Curva de Volatilidade Impl√≠cita Aprendida (Vencimento Fixo)')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36100656",
   "metadata": {},
   "source": [
    "### An√°lise em rela√ß√£o a moneyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA: Erro por moneyness (usa val_loader)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'val_loader' not in globals():\n",
    "    print(\"val_loader n√£o encontrado. Crie/defina val_loader antes de rodar esta c√©lula.\")\n",
    "else:\n",
    "    model.eval()\n",
    "    moneyness_vals = []\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, premiums_real in val_loader:\n",
    "            S_norm = inputs[:, 0].cpu()\n",
    "            K_norm = inputs[:, 1].cpu()\n",
    "            S = S_norm * (data_stats['S_max'] - data_stats['S_min']) + data_stats['S_min']\n",
    "            K = K_norm * (data_stats['K_max'] - data_stats['K_min']) + data_stats['K_min']\n",
    "            moneyness = (S / K).numpy()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            price_pred = model(inputs)['price'].cpu().numpy().flatten()\n",
    "            premiums = premiums_real.cpu().numpy().flatten()\n",
    "\n",
    "            valid_indices = premiums > 1e-6\n",
    "            if valid_indices.sum() == 0:\n",
    "                continue\n",
    "            error_pct = (price_pred[valid_indices] - premiums[valid_indices]) / premiums[valid_indices]\n",
    "\n",
    "            moneyness_vals.extend(moneyness[valid_indices])\n",
    "            errors.extend(error_pct)\n",
    "\n",
    "    moneyness_vals = np.array(moneyness_vals)\n",
    "    errors = np.array(errors)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    plt.scatter(moneyness_vals, errors, alpha=0.1)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.xlabel('Moneyness (S/K)')\n",
    "    plt.ylabel('Erro Percentual de Previs√£o ((Prev - Real) / Real)')\n",
    "    plt.title('Distribui√ß√£o do Erro de Previs√£o por Moneyness')\n",
    "    plt.grid(True)\n",
    "\n",
    "    os.makedirs(PATHS['plot_save_dir'], exist_ok=True)\n",
    "    save_path = os.path.join(PATHS['plot_save_dir'], 'error_by_moneyness.png')\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print(f\"Gr√°fico de erro por moneyness salvo em: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
